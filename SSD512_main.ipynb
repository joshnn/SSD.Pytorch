{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled22.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjekyBJnfoEajIe6nKWbJ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshnn/SSD.Pytorch/blob/master/SSD512_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSl_AhHDBQd3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "443e392b-4c7e-4d3e-90d1-75644cd02690"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/joshnn/SSD.Pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'SSD.Pytorch'...\n",
            "remote: Enumerating objects: 229, done.\u001b[K\n",
            "remote: Counting objects: 100% (229/229), done.\u001b[K\n",
            "remote: Compressing objects: 100% (177/177), done.\u001b[K\n",
            "remote: Total 229 (delta 89), reused 158 (delta 41), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (229/229), 11.53 MiB | 6.49 MiB/s, done.\n",
            "Resolving deltas: 100% (89/89), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GbFoLA1C1O5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "1ebd1d45-78b5-447d-cf41-884e0c4caa59"
      },
      "source": [
        "%cd SSD.Pytorch\n",
        "!mkdir weights\n",
        "!cd weights\n",
        "!wget https://s3.amazonaws.com/amdegroot-models/vgg16_reducedfc.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SSD.Pytorch\n",
            "--2020-09-25 02:17:24--  https://s3.amazonaws.com/amdegroot-models/vgg16_reducedfc.pth\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.83.110\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.83.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 81938914 (78M) [binary/octet-stream]\n",
            "Saving to: ‘vgg16_reducedfc.pth’\n",
            "\n",
            "vgg16_reducedfc.pth 100%[===================>]  78.14M  16.1MB/s    in 6.0s    \n",
            "\n",
            "2020-09-25 02:17:30 (12.9 MB/s) - ‘vgg16_reducedfc.pth’ saved [81938914/81938914]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROcBk3rfLcDX",
        "colab_type": "text"
      },
      "source": [
        "コードの評価は次のように行える。\n",
        "- Pascal VOCをダウンロードし、Trainを行う\n",
        "- Demoのため事前学習モデルをダウンロードする\n",
        "\n",
        "Trainの場合、次から8.4GBのデータをダウンロードし学習させる。学習時間を想定しておく必要がある。\n",
        "- https://gluon-cv.mxnet.io/build/examples_datasets/pascal_voc.html#:~:text=Pascal%20VOC%20is%20a%20collection,and%202007%20test%20for%20validation\n",
        "\n",
        "Demoの場合、Baiduからモデルをダウンロードする。これに必要なクライアントソフトをインストールすることを避けるためここでは行わない。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiWNvYQqC6Fk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "bf2f67e0-b1c0-4f91-990b-8775b22574b0"
      },
      "source": [
        "%cd /content/SSD.Pytorch\n",
        "!CUDA_VISIBLE_DEVICES=0 python train.py --input 512 --dataset_root ./data/VOCdevkit --num_class 21 --num_epoch 300 --lr 0.001 --batch_size 16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SSD.Pytorch\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 285, in <module>\n",
            "    train()\n",
            "  File \"train.py\", line 94, in train\n",
            "    MEANS))\n",
            "  File \"/content/SSD.Pytorch/data/voc0712.py\", line 111, in __init__\n",
            "    for line in open(osp.join(rootpath, 'ImageSets', 'Main', name + '.txt')):\n",
            "FileNotFoundError: [Errno 2] No such file or directory: './data/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfdWpx6ZHkP1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "12d763a9-9643-4280-db9d-2ef8c8bb3a09"
      },
      "source": [
        "!python eval.py --input 512 --trained_model weights/ssd512_VOC_73000_mAP79.80.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG base: [Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True), Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False), Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6)), ReLU(inplace=True), Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1)), ReLU(inplace=True)]\n",
            "input channels: 128\n",
            "extras layers: [Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1)), Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)), Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1)), Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)), Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1)), Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)), Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1)), Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)), Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1)), Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))]\n",
            "VGG16 output size: 35\n",
            "extra layer size: 10\n",
            "extra layer 0 : Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "extra layer 1 : Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "extra layer 2 : Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "extra layer 3 : Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "extra layer 4 : Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "extra layer 5 : Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "extra layer 6 : Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "extra layer 7 : Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "extra layer 8 : Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "extra layer 9 : Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "Begin to build SSD-VGG...\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"eval.py\", line 426, in <module>\n",
            "    net.load_state_dict(torch.load(args.trained_model))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 571, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 229, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 210, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'weights/ssd512_VOC_73000_mAP79.80.pth'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyZZYrStHn1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls weights"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}